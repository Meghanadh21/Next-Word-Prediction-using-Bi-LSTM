{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivek\\anaconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: better-profanity in c:\\users\\vivek\\anaconda3\\envs\\project\\lib\\site-packages (0.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import wikipediaapi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "# Install the better-profanity module\n",
    "%pip install better-profanity\n",
    "\n",
    "from better_profanity import profanity\n",
    "\n",
    "# Load the profanity filter with its default list\n",
    "profanity.load_censor_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vivek\\anaconda3\\envs\\project\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Synthetic dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def generate_synthetic_text(prompts, num_sentences=5, file_name=\"synthetic_text.txt\"):\n",
    "    generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "    data = \"\"\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        result = generator(prompt, max_length=50, num_return_sequences=num_sentences)\n",
    "        for output in result:\n",
    "            data += output['generated_text'] + \"\\n\"\n",
    "    \n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    print(\"✅ Synthetic dataset saved successfully!\")\n",
    "\n",
    "# Example Prompts\n",
    "prompts = [\"Once upon a time in a distant land,\", \"The future of artificial intelligence is\"]\n",
    "generate_synthetic_text(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Synthetic dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example Prompts\n",
    "prompts = [\"Once upon a time in a distant land,\", \"The future of artificial intelligence is\"]\n",
    "generate_synthetic_text(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading & Preprocessing\n",
    "dataset_path = 'combined_dataset.txt'\n",
    "with open(dataset_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning (lowercase and strip extra spaces)\n",
    "text_data = text_data.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and saving tokenizer for later use\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text_data])\n",
    "pickle.dump(tokenizer, open('tokenizer1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "sequence_data = tokenizer.texts_to_sequences([text_data])[0]\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text using Keras Tokenizer\n",
    "tokenizer_lstm = Tokenizer()\n",
    "tokenizer_lstm.fit_on_texts([text_data])\n",
    "total_words = len(tokenizer_lstm.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences with 5-word context\n",
    "sequence_length = 5\n",
    "sequences = []\n",
    "for i in range(sequence_length, len(sequence_data)):\n",
    "    sequences.append(sequence_data[i - sequence_length:i + 1])\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input (X) and output (y)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "X = pad_sequences(X, maxlen=sequence_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, using random embeddings\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.random.uniform(-1, 1, (vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences (n-gram sequences)\n",
    "input_sequences = []\n",
    "for line in text_data.split('\\n'):\n",
    "    token_list = tokenizer_lstm.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=sequence_length, trainable=True),\n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping and learning rate adjustment\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 185ms/step - accuracy: 0.0366 - loss: 6.7434 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - accuracy: 0.0890 - loss: 5.6362 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 182ms/step - accuracy: 0.1186 - loss: 5.2041 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.1352 - loss: 4.8405 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 187ms/step - accuracy: 0.1582 - loss: 4.4642 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 190ms/step - accuracy: 0.1797 - loss: 4.1379 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 187ms/step - accuracy: 0.2065 - loss: 3.7892 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 190ms/step - accuracy: 0.2497 - loss: 3.4116 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m19/87\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - accuracy: 0.3126 - loss: 2.9607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_reduction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\vivek\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=50, batch_size=256, verbose=1, callbacks=[early_stopping, lr_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.7593 - loss: 0.8449 - val_accuracy: 0.6657 - val_loss: 1.1600 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 63ms/step - accuracy: 0.7622 - loss: 0.8321 - val_accuracy: 0.6514 - val_loss: 1.2703 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 62ms/step - accuracy: 0.7715 - loss: 0.8069 - val_accuracy: 0.6398 - val_loss: 1.3470 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 65ms/step - accuracy: 0.7809 - loss: 0.7672 - val_accuracy: 0.6174 - val_loss: 1.4494 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.8111 - loss: 0.6581 - val_accuracy: 0.6351 - val_loss: 1.3602 - learning_rate: 5.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.8412 - loss: 0.5298 - val_accuracy: 0.6448 - val_loss: 1.3279 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Adjust callbacks with a bit more patience for learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X, y, epochs=10, batch_size=64, verbose=1,\n",
    "                    callbacks=[early_stopping, lr_reduction],\n",
    "                    validation_split=0.2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictors and labels for training the LSTM (optional)\n",
    "xs = input_sequences[:, :-1]\n",
    "labels = input_sequences[:, -1]\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT fill-mask pipeline (pre-trained model provided)\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "def predict_next_word_bert(text):\n",
    "    \"\"\"\n",
    "    Predicts the next word using BERT's masked language model.\n",
    "    It appends a [MASK] token at the end of the input text.\n",
    "    \"\"\"\n",
    "    masked_text = text + \" [MASK].\"  # Append mask token for prediction\n",
    "    predictions = fill_mask(masked_text)\n",
    "    \n",
    "    print(f\"\\n🔹 Input: {text}\")\n",
    "    for idx, prediction in enumerate(predictions[:3]):  # Display top 3 predictions\n",
    "        word = prediction['token_str']\n",
    "        confidence = prediction['score'] * 100\n",
    "        print(f\"   ➤ Prediction {idx+1}: {word} ({confidence:.2f}%)\")\n",
    "    \n",
    "    # Return the top predicted word\n",
    "    return predictions[0]['token_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Input: give me the best price\n",
      "   ➤ Prediction 1: possible (48.34%)\n",
      "   ➤ Prediction 2: ever (43.73%)\n",
      "   ➤ Prediction 3: available (1.18%)\n",
      "\n",
      "✅ Predicted next word: possible\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Example Usage\n",
    "input_sentence = \"give me the best price\"\n",
    "next_word = predict_next_word_bert(input_sentence)\n",
    "print(f\"\\n✅ Predicted next word: {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Input: Hello ! Good\n",
      "   ➤ Prediction 1: morning (75.54%)\n",
      "   ➤ Prediction 2: afternoon (6.61%)\n",
      "   ➤ Prediction 3: evening (5.45%)\n",
      "\n",
      "Predicted next word: morning\n"
     ]
    }
   ],
   "source": [
    "# For example, using input() in a terminal or ipywidgets in a notebook.\n",
    "user_input = input(\"Enter your prompt (without the next word): \")\n",
    "predicted = predict_next_word_bert(user_input)\n",
    "print(f\"\\nPredicted next word: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store user input data for later tokenizer updates\n",
    "def store_user_input(text):\n",
    "    with open(\"user_data.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(text + \"\\n\")\n",
    "\n",
    "# Function to update the tokenizer with new user data\n",
    "def update_tokenizer():\n",
    "    try:\n",
    "        with open(\"user_data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            new_text_data = f.read()\n",
    "        global tokenizer\n",
    "        tokenizer.fit_on_texts([new_text_data])\n",
    "        pickle.dump(tokenizer, open('tokenizer1.pkl', 'wb'))\n",
    "        print(\"✅ Tokenizer updated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error updating tokenizer: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT fill-mask pipeline for next word prediction\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Function to predict the next word using BERT while filtering out profanities\n",
    "def predict_next_word_bert(text):\n",
    "    masked_text = text + \" [MASK].\"  # Append mask token for prediction\n",
    "    predictions = fill_mask(masked_text)\n",
    "    \n",
    "    print(f\"\\n🔹 Input: {text}\")\n",
    "    # Display top 3 predictions with filtering\n",
    "    for idx, prediction in enumerate(predictions[:3]):\n",
    "        word = prediction['token_str']\n",
    "        if not profanity.contains_profanity(word):\n",
    "            print(f\"   ➤ Prediction {idx+1}: {word} ({prediction['score']*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"   ➤ Prediction {idx+1}: [Filtered]\")\n",
    "    \n",
    "    # Return the first non-offensive word; if none found, return a default word\n",
    "    for prediction in predictions:\n",
    "        if not profanity.contains_profanity(prediction['token_str']):\n",
    "            return prediction['token_str']\n",
    "    return \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Input: give me the best price\n",
      "   ➤ Prediction 1: possible (48.34%)\n",
      "   ➤ Prediction 2: ever (43.73%)\n",
      "   ➤ Prediction 3: available (1.18%)\n",
      "\n",
      "✅ Predicted next word: possible\n",
      "\n",
      "🔹 Input: Good morning\n",
      "   ➤ Prediction 1: everyone (3.93%)\n",
      "   ➤ Prediction 2: sir (2.41%)\n",
      "   ➤ Prediction 3: everybody (1.05%)\n",
      "\n",
      "🔹 Input: Good morning everyone\n",
      "   ➤ Prediction 1: ##s (27.60%)\n",
      "   ➤ Prediction 2: else (5.95%)\n",
      "   ➤ Prediction 3: here (5.11%)\n",
      "\n",
      "🔹 Input: Good morning everyone ##s\n",
      "   ➤ Prediction 1: ! (1.32%)\n",
      "   ➤ Prediction 2: mr (1.22%)\n",
      "   ➤ Prediction 3: \" (1.09%)\n",
      "\n",
      "Predicted sentence: Good morning everyone ##s !\n",
      "✅ Tokenizer updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to iteratively predict the next num_words words\n",
    "def Predict_Next_Words(text, num_words):\n",
    "    store_user_input(text)  # Save user input for future tokenizer updates\n",
    "    predicted_sentence = text\n",
    "    for _ in range(num_words):\n",
    "        next_word = predict_next_word_bert(predicted_sentence)\n",
    "        predicted_sentence += \" \" + next_word.strip()\n",
    "    return predicted_sentence\n",
    "\n",
    "# Example Usage\n",
    "input_sentence = \"give me the best price\"\n",
    "next_word = predict_next_word_bert(input_sentence)\n",
    "print(f\"\\n✅ Predicted next word: {next_word}\")\n",
    "\n",
    "user_input = input(\"Enter your prompt (without the next word): \")\n",
    "predicted = Predict_Next_Words(user_input, 3)\n",
    "print(f\"\\nPredicted sentence: {predicted}\")\n",
    "\n",
    "# Optionally, update the tokenizer after predictions\n",
    "update_tokenizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
